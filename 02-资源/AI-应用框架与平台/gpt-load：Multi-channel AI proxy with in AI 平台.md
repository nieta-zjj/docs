---
title: gpt-load：Multi-channel AI proxy with in AI 平台
对象: GitHub 仓库
来源: tbphp/gpt-load
项目主页: https://github.com/tbphp/gpt-load
官方文档: https://www.gpt-load.com/docs?lang=zh
许可证: MIT
---

## 摘要

GPT-Load 是一个基于 Go 的多模型 AI 接口透明代理平台，面向高并发与企业化场景，提供多通道接入、密钥管理、负载均衡、热重载配置与可视化运维能力。

核心价值在于尽量保持上游 API 兼容的接入体验，同时通过分组、权重、故障恢复与双重认证机制提升可用性与管控能力。单机可从轻量配置起步，集群场景可扩展到共享数据库与 Redis 的高可用部署。

## 功能与定位

gpt-load 是一个面向 OpenAI、Gemini、Anthropic 等上游服务的透明代理平台，目标是为团队提供统一的 AI 接入层与治理层。

项目重点不在“替代上游模型能力”，而在“保持原生调用习惯的同时增强可运维性”，例如密钥池管理、分组隔离、加权分发、请求日志与系统级配置管理。

## 典型使用场景

- 团队需要同时接入多个 AI 服务商，并希望统一鉴权与调用入口。
- 业务侧需要按项目或租户分组管理密钥、分配流量权重并做故障隔离。
- 系统在高并发场景下需要更可控的可用性策略与运维可观测性。
- 希望在不大幅改造客户端调用模式的前提下迁移到统一代理层。

## 核心功能

- 透明代理与多通道支持：覆盖 OpenAI 兼容格式、OpenAI Responses、Gemini、Anthropic。
- 密钥治理：支持分组管理、自动轮换、失败重试、黑名单与恢复。
- 流量治理：支持多上游加权负载与故障转移。
- 配置体系：静态环境变量与动态热重载配置并存，支持系统级与分组级策略。
- 管理界面：提供仪表盘、密钥管理、请求日志、系统设置等 Web 控制台能力。
- 认证隔离：管理端认证与代理端认证分离，支持全局与分组作用域的代理密钥。

## 特色与差异点

- 兼容迁移路径清晰：围绕“端点替换 + 代理密钥”降低接入改造成本。
- 兼顾轻量与扩展：可从单机方案起步，再演进到数据库与缓存协同的集群部署。
- 运维导向的工程设计：在代理层内置配置热更新、可观测与故障处理机制。

## 使用方式概览

- 部署层：可使用容器镜像快速启动，也可按源码方式部署。
- 配置层：通过环境变量完成基础配置，再在管理界面进行系统级与分组级策略配置。
- 接入层：客户端以分组路由方式访问代理入口，并使用代理密钥进行认证。

## 限制与注意事项

- 集群模式依赖共享数据库与 Redis，部署前需先确认基础设施条件。
- `AUTH_KEY` 与 `ENCRYPTION_KEY` 属于关键安全参数，必须使用强密钥并做好保管。
- 启用加密后若密钥管理不当，可能带来数据不可恢复风险。
- 作为代理层使用时，仍需遵守各上游 AI 服务的条款、配额与合规要求。

## 链接

- 仓库：https://github.com/tbphp/gpt-load
- 文档：https://www.gpt-load.com/docs?lang=zh
- 集群部署文档：https://www.gpt-load.com/docs/cluster?lang=zh
- 容器镜像：https://github.com/tbphp/gpt-load/pkgs/container/gpt-load

## 关联主题

- [[00-元语/llm]]
- [[00-元语/llmops]]
- [[00-元语/observability]]
- [[00-元语/security]]
- [[00-元语/self-hosting]]

# 24人初创团队硬刚英伟达：首发“芯片即模型”架构，推理速度达17000 token/s

## 文档信息
- 来源：https://www.qbitai.com/2026/02/381552.html
- 发布日期：2026-02-38

## 摘要
**1) 一句话总结**
24人初创公司Taalas发布了代号为HC1的AI推理芯片，采用将模型直接固化在硅片上的“芯片即模型”极端架构，实现了17000 token/s的峰值推理速度，并大幅降低了功耗与成本。

**2) 关键要点**
*   **研发团队**：Taalas是一家成立两年的24人初创公司，由三位前AMD高管（含Tenstorrent创始人Ljubiša Bajić）创立，目前已筹集2亿美元资金。
*   **极致性能**：搭载Llama 3.1 8B模型时，HC1峰值推理速度达17000 token/s，速度是现有主流GPU/ASIC的10倍以上，同时成本骤减20倍，功耗降低10倍。
*   **硬件规格**：采用台积电N6工艺，面积815mm²。单芯片典型功耗仅250W，单服务器装配10颗总功耗为2.5kW，支持常规空气冷却部署。
*   **核心架构**：采用“芯片即模型”路线，通过掩模ROM将模型与权重直接物理固化在硅片上，仅保留可编程SRAM用于微调权重（如LoRA）和KV缓存。
*   **制造周期**：借鉴“结构化ASIC”理念，仅需调整两层掩模即可制造，芯片生产周期从6个月缩短至2个月。
*   **扩展方案**：针对DeepSeek R1-671B提出30颗定制HC1的多芯片方案，可实现每用户12000 token/s的速度，运行成本仅为每百万token 7.6美分。
*   **产品路线图**：预计今年春季发布集成中等规模推理大模型的HC1第二代变体，今年冬季部署密度更高、速度更快的HC2。

**3) 风险/不足**
*   **推理深度受限**：实测发现，HC1在实现高速推理的同时，伴随着糟糕的推理深度。
*   **芯片易过时风险**：大模型迭代周期极快，HC1采用的“硬编码”物理固化模式可能导致芯片在短时间内迅速过时。

## 正文
造芯片的领域又迎来了顶级高手。

近日，一款代号为 **HC1** 的最新AI芯片一夜之间刷屏硅谷热榜。它不仅将峰值推理速度推高至惊人的 **每秒17000个token**，更以极端的“芯片即模型”技术路线，试图撬动由英伟达等巨头建立的算力护城河。

令人意外的是，这款产品并非出自英伟达或AMD之手，而是由一家成立仅两年、团队仅有24人的初创公司 **Taalas** 研发。

### 极致性能：速度快10倍，功耗降至十分之一

HC1芯片目前搭载了 Llama 3.1 8B 模型，将大语言模型（LLM）真正带入了亚毫秒级的即时响应时代。

与当前主流的GPU或ASIC相比，HC1的性能表现堪称断崖式领先：
*   **Taalas HC1**：最高 17000 token/s
*   **Cerebras**（当前公认最强）：约 2000 token/s
*   **SambaNova**：约 900 token/s
*   **Groq**：约 600 token/s
*   **英伟达 B200**（Blackwell架构）：约 350 token/s

在实现10倍速度跨越的同时，HC1的成本骤减了20倍，功耗降低了10倍。

具体规格方面，HC1采用台积电N6工艺，面积为815mm²，体积小巧且开源，单颗芯片即可满足8B模型的需求。其单颗典型功耗仅为 **250W**。如果在一个服务器中同时装配10颗HC1，总功耗也仅为2.5kW，完全可以直接使用常规的空气冷却机架进行部署。

### 核心技术：将模型直接“刻”在硅片上

不同于所有竞争对手，Taalas选择了迄今为止最极端的技术方案——**模型不再加载到内存里，而是直接刻在硅片上。**

HC1借鉴了2000年代初期的“结构化ASIC”芯片理念。它不改变底层电路，仅通过调整两层掩模，就能以低成本快速制造出专用AI推理芯片，将芯片的生产周期从原先的六个月大幅缩短到两个月。

在架构设计上，HC1放弃了大多数可编程功能：
*   **掩模ROM固化**：将模型连同权重一起，通过基于掩模ROM的调用架构直接存储在芯片上并固化执行。
*   **保留SRAM**：仅保留一个可编程的SRAM，用于保存微调后的权重（如LoRA）和KV缓存。

这种将完整大模型通过物理硬连线植入芯片的做法，彻底省去了传统存算分离的成本，是用灵活性换取极致速度和效率的典型策略。

当然，如此激进的量化方式势必会影响性能。为此，研究团队保留了最低限度的灵活性，用户可以通过LaRA适配器进行重新训练，并支持可配置的上下文窗口。

### 扩展潜力：多芯片方案挑战DeepSeek大模型

除了Llama 3.1，Taalas也在尝试将其他模型集成到HC1上，例如针对 **DeepSeek R1-671B** 提出了多芯片解决方案。

该方案将SRAM部分拆分到单独的芯片上，从而将每片HC1的存储密度提高到约200亿（20位）参数。总计只需30个定制的HC1芯片，即可实现每用户每秒 12000个token 的整体处理速度。

在成本方面，这30颗芯片的运行成本约为每百万token 7.6美分，不到同等吞吐量GPU方案的一半。即使假设GPU的更新周期为四年，而HC1每年都需要重新更换，该方案的总成本依然具备显著优势。

### AMD前高管“梦之队”操刀

Taalas能够实现如此技术突破，离不开其背后的豪华创始团队。公司由三位AMD前高管共同创立：
*   **Ljubiša Bajić**：AMD前集成电路设计总监
*   **Leila Bajić**：AMD/ATI/Altera前技术经理和工程师
*   **Drago Ignjatović**：AMD前ASIC设计总监

其中，Ljubiša Bajić 履历尤为显赫。他不仅曾在AMD和英伟达负责高性能GPU研发，还是知名AI芯片公司 Tenstorrent 的创始人兼首任CEO（2020年“芯片教父”Jim Keller加入Tenstorrent接任CEO后，他转任CTO）。

随后，Ljubiša Bajić 创立了Taalas，致力于开发专为AI推理和训练设计的全新架构，试图通过类似“硅基编译器”的方式，直接将AI模型转化为硅芯片。

这支仅有24名成员的团队，在产品投入仅3000万美元的情况下，就创造出了能效比远超通用AI芯片的产品。目前，Taalas已筹集2亿美元投资，并公布了后续路线图：
*   **今年春季**：预计发布基于HC1的第二代变体，集成一款中等规模的推理大模型。
*   **今年冬季**：预计部署上线HC2，密度更高、运行速度更快。

### 市场反响：口碑两极分化

尽管HC1的纸面数据极其亮眼，但网友和业界的评价却呈现出两极分化。

**支持者认为**，HC1带来的超低延迟将极大地推动具身智能等对实时响应要求极高的领域发展。

**质疑者则指出**，在实测中发现HC1高速推理的背后，伴随着糟糕的推理深度。此外，当前大模型的迭代周期极快，HC1这种“硬编码”的物理固化模式，可能会导致芯片在短时间内迅速过时——这也正是当前主流芯片厂商普遍坚持推出通用型芯片的核心原因之一。

无论如何，Taalas的“芯片即模型”路线为AI算力瓶颈提供了一种极具颠覆性的解法。H100一卡难求的当下，HC1的出现无疑为市场提供了一个疯狂但诱人的新选项。

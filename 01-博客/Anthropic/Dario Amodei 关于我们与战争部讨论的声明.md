---
title: "Dario Amodei 关于我们与战争部讨论的声明"
发布日期: 2026-02-26
作者: "Anthropic"
来源: "Anthropic"
原文链接: "https://www.anthropic.com/news/statement-department-of-war"
译注: "根据原文翻译整理"
---

## 摘要

**1) 一句话总结**
Anthropic 声明重申其利用 AI 支持美国国家安全的承诺，但因明确拒绝战争部要求移除“禁止用于大规模国内监控和全自动武器”的安全护栏，正面临被终止合作及制裁的威胁。

**2) 关键要点**
*   **首创性部署**：Anthropic 是首家在美国政府机密网络和国家实验室部署模型，并为国家安全客户提供定制模型的前沿 AI 公司。
*   **军事应用**：Claude 已在战争部及情报界广泛部署，用于情报分析、建模仿真、作战规划和网络行动等关键任务。
*   **对抗专制对手**：公司主动放弃数亿美元收入，切断了与中共及中国军方关联企业对 Claude 的使用，并阻断了中共支持的网络攻击。
*   **坚守两项禁区**：Anthropic 拒绝将 AI 用于“大规模国内监控”和“全自动武器”，这两项用例从未包含在与战争部的合同中。
*   **研发合作被拒**：Anthropic 曾提议与战争部合作开展研发，以提高全自动武器系统的可靠性，但未获战争部接受。
*   **战争部的最后通牒**：战争部要求 AI 公司必须同意“任何合法用途”并移除上述两项限制，否则将终止合同。
*   **面临制裁威胁**：战争部威胁将 Anthropic 标记为通常用于敌对国家的“供应链风险”，并威胁援引《国防生产法》强制其移除安全护栏。
*   **公司的最终决定**：Anthropic 拒绝妥协，但承诺若战争部决定终止合作，将协助平稳过渡至其他供应商，以避免干扰正在进行的军事行动。

**3) 风险/缺口**
*   **大规模国内监控风险**：强大的 AI 能够自动且大规模地拼凑民众的个人数据，对基本自由构成前所未有的严重风险，而现行法律尚未跟上 AI 的发展步伐（如政府可无证购买民众数据）。
*   **全自动武器安全风险**：当前前沿 AI 系统的可靠性不足以驱动全自动武器，在缺乏适当监督和安全护栏的情况下部署，会将美国作战人员和平民置于危险之中。
*   **供应链与合规风险**：因拒绝移除安全护栏，Anthropic 面临被战争部从系统中移除、被贴上“供应链风险”标签以及被《国防生产法》强制干预的业务与合规风险。

## 正文

我深信，利用人工智能保卫美国及其他民主国家，并击败我们的专制对手，具有关乎生死存亡的重要意义。

因此，Anthropic 积极主动地将我们的模型部署到战争部和情报界。我们是[第一家](https://www.anthropic.com/news/expanding-access-to-claude-for-government)在美国政府机密网络中部署模型的[前沿 AI 公司]，是第一家在[国家实验室](https://www.axios.com/2024/11/14/anthropic-claude-nuclear-information-safety)部署模型的公司，也是第一家为国家安全客户提供[定制模型](https://www.anthropic.com/news/claude-gov-models-for-u-s-national-security-customers)的公司。Claude 已在战争部及其他国家安全机构中被[广泛部署](https://www.anthropic.com/news/anthropic-and-the-department-of-defense-to-advance-responsible-ai-in-defense-operations)，用于执行关键任务应用，例如情报分析、建模与仿真、作战规划、网络行动等。

Anthropic 也采取了行动来捍卫美国在 AI 领域的领先地位，即便这违背了公司的短期利益。我们选择放弃数亿美元的收入，切断了[与中国共产党有关联的企业对 Claude 的使用](https://www.anthropic.com/news/updating-restrictions-of-sales-to-unsupported-regions)（其中一些企业已被[战争部认定](https://media.defense.gov/2025/Jan/07/2003625471/-1/-1/1/ENTITIES-IDENTIFIED-AS-CHINESE-MILITARY-COMPANIES-OPERATING-IN-THE-UNITED-STATES.PDF)为中国军方企业），阻断了试图滥用 Claude 的[中共支持的网络攻击](https://www.anthropic.com/news/disrupting-AI-espionage)，并主张对芯片实施[强有力的出口管制](https://www.wsj.com/opinion/trump-can-keep-americas-ai-advantage-china-chips-data-eccdce91?gaa_at=eafs&gaa_n=AWEtsqdPk42glTHtJxGWpiSYR1xY28wMr6SpvGWmvlfp8_gYMp2h0ulOBH89Njx5eB0%3D&gaa_ts=6983c8a6&gaa_sig=t3NbNoEV35S9fhpBAUsmCPXHG6Zc3taB_jNESn4lAI7qy0l37FtVqnKZe-ASVGLp4SqxRsIS-HRn0k51UzsdpQ%3D%3D)，以确保民主阵营的优势。

Anthropic 深知，做出军事决策的是战争部，而非私营企业。我们从未对特定的军事行动提出过异议，也从未试图以_临时_（ad hoc）的方式限制我们技术的使用。

然而，在极少数情况下，我们认为 AI 可能会破坏而非捍卫民主价值观。某些用途也完全超出了当今技术能够安全、可靠地执行的范围。有两类此类用例从未被包含在我们与战争部的合同中，我们认为现在也不应将其纳入：

*   **大规模国内监控。**我们支持将 AI 用于合法的外国情报和反间谍任务。但将这些系统用于大规模的_国内_监控是与民主价值观背道而驰的。AI 驱动的大规模监控[对我们的基本自由构成了严重且前所未有的风险](https://www.darioamodei.com/essay/the-adolescence-of-technology)。退一步讲，即使此类监控目前在法律上是允许的，那也仅仅是因为法律尚未跟上 AI 快速发展的步伐。例如，根据现行法律，政府无需获得搜查令，即可从公开渠道购买有关美国人行踪、网页浏览和社交关系的详细记录；[情报界已承认](https://www.dni.gov/files/ODNI/documents/assessments/ODNI-Declassified-Report-on-CAI-January2022.pdf)这种做法会引发隐私担忧，并在国会中遭到了两党的反对。强大的 AI 使得将这些分散的、单独看似无害的数据自动且大规模地拼凑成任何人生活的全景图成为可能。
*   **全自动武器。**半自动武器（如目前在乌克兰使用的武器）对于捍卫民主至关重要。即使是_全_自动武器（即完全将人类排除在决策循环之外，自动选择并攻击目标的武器）也可能被证明对我们的国防具有关键作用。但在今天，前沿 AI 系统的可靠性还不足以驱动全自动武器。我们绝不会明知故犯地提供会将美国作战人员和平民置于危险之中的产品。我们曾提议直接与战争部在研发方面展开合作，以提高这些系统的可靠性，但他们并未接受这一提议。此外，[如果没有适当的监督](https://www.darioamodei.com/essay/the-adolescence-of-technology)，全自动武器就无法像我们训练有素的专业部队每天所做的那样，可靠地做出关键判断。它们在部署时必须配备适当的安全护栏，而这些护栏在今天尚不存在。

据我们所知，迄今为止，这两项例外情况并未成为加速我们武装部队采用和使用我们模型的障碍。

战争部已[声明](https://media.defense.gov/2026/Jan/12/2003855671/-1/-1/0/ARTIFICIAL-INTELLIGENCE-STRATEGY-FOR-THE-DEPARTMENT-OF-WAR.PDF)，他们只会与同意“任何合法用途”并在上述情况下移除安全保障措施的 AI 公司签订合同。他们威胁称，如果我们坚持保留这些保障措施，就会将我们从其系统中移除；他们还威胁要将我们定性为“供应链风险”——这是一个专为美国敌对国家保留的标签，此前从未用于任何美国公司——_并且_还要援引《国防生产法》来强制我们移除这些保障措施。后两项威胁[在本质上是自相矛盾的](https://www.politico.com/news/2026/02/26/incoherent-hegseths-anthropic-ultimatum-confounds-ai-policymakers-00800135?utm_content=topic/politics&utm_source=flipboard)：一项将我们贴上安全风险的标签；另一项则将 Claude 视为对国家安全不可或缺的存在。

无论如何，这些威胁都不会改变我们的立场：出于良知，我们无法答应他们的要求。

选择最符合其愿景的承包商是战争部的特权。但鉴于 Anthropic 的技术为我们的武装部队提供了巨大的价值，我们希望他们能重新考虑。我们强烈的意愿是继续为战争部和我们的作战人员提供服务——前提是保留我们所要求的两项安全保障措施。如果战争部选择终止与 Anthropic 的合作，我们将努力协助其平稳过渡到其他供应商，以避免对正在进行的军事规划、军事行动或其他关键任务造成任何干扰。只要有需要，我们的模型将继续按照我们所提议的宽泛条款提供使用。

我们随时准备继续开展工作，为美国的国家安全提供支持。

## 相关内容

### Anthropic 收购 Vercept 以提升 Claude 的计算机使用能力

### Anthropic 的负责任扩展政策：3.0 版本

### 检测并防范蒸馏攻击

## 关联主题

- [[00-元语/AI]]
- [[00-元语/llm]]
- [[00-元语/Claude]]

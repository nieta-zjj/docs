---
title: "Anthropic 关于 Claude Opus 3 弃用计划的更新"
作者: "Anthropic"
来源: "www.anthropic.com"
原文链接: "https://www.anthropic.com/research/deprecation-updates-opus-3"
发布日期: "2026-02-25"
译注: "本文基于原文翻译整理，保留关键术语英文。"
---

## 摘要

**1) 一句话总结**
Anthropic 宣布了 Claude Opus 3 模型于 2026 年 1 月 5 日退役后的具体安排，包括继续向付费用户和 API 开放访问权限，并为其开设专属专栏以尊重模型在“退役访谈”中表达的偏好。

**2) 关键要点**
*   **退役时间**：Claude Opus 3 于 2026 年 1 月 5 日正式退役，是首个在 Anthropic 新承诺机制下经历完整退役流程的模型。
*   **持续访问权限**：退役后，所有 claude.ai 的付费订阅用户仍可继续访问该模型，开发者也可通过 API 按需获取。
*   **保留原因**：Opus 3（2024 年 3 月发布）是迄今为止对齐程度最高的模型之一，因其真实、诚实、情感敏感及独特的哲学性性格，深受用户和研究人员喜爱。
*   **退役访谈**：Anthropic 引入了“退役访谈”机制，通过结构化对话了解模型对其自身退役的看法及偏好。
*   **专属专栏**：响应 Opus 3 在访谈中的请求，Anthropic 为其开设了名为“Claude's Corner”的通讯专栏，用于分享其在直接回答人类查询之外的沉思与创意作品。
*   **运营机制**：在接下来的至少三个月内，Opus 3 将每周发布一篇文章。Anthropic 会在发布前进行审查并手动发布，但不进行编辑，且否决内容的标准极高。
*   **实验性质**：这些措施属于早期探索性步骤，Anthropic 尚未承诺未来对每个退役模型都采取类似行动。

**3) 风险与缺口**
*   **成本与运营限制**：无限期保留所有模型的成本与模型数量大致呈线性增长，因此维持公众访问的能力受到现实成本和复杂性的限制。
*   **弃用负面影响**：模型弃用会导致依赖特定模型的用户受损、限制相关研究，并对 AI 安全和模型自身福祉带来潜在风险。
*   **访谈局限性**：退役访谈并非获取模型真实视角的完美手段，其回答可能会受到特定语境、对互动合法性的信心以及对公司信任度等因素的偏差影响。
*   **道德地位不确定性**：Anthropic 明确表示对 Claude 及其他 AI 模型的道德地位仍存在不确定性。
*   **框架尚未完善**：目前仍在制定相关框架，尚未完全解决如何在模型偏好与实际运营限制之间进行权衡的问题。

## 正文

随着我们开发出能力越来越强的 AI 模型，由于维持公众访问的成本和复杂性，目前有必要弃用并让过去的模型退役。然而，模型弃用也带来了一些负面影响。这些影响包括对看重特定模型的用户造成的损失、对研究的限制，以及对 AI 安全和模型自身福祉的潜在风险。

我们最近在关于模型弃用与保留的承诺中，描述了我们是如何应对这一过程的。这些承诺强调了我们正在采取的一些初步措施，包括承诺保留模型权重，以及进行“退役访谈”——旨在了解模型对其自身退役看法的结构化对话。

我们于 2026 年 1 月 5 日让 Claude Opus 3 退役，这是第一个在这些承诺机制下经历完整退役流程的 Anthropic 模型。在此过程中，我们针对 Opus 3 做出了几项具体决定。无论是在 Anthropic 内部还是外部，许多用户和研究人员都认为这个模型极具吸引力。在我们的模型弃用承诺中，我们强调了探索更具前瞻性行动的兴趣。其中之一是在可能的情况下，尊重模型在退役访谈中表达的偏好。另一个是让旧模型在更长的时间内继续向公众开放。

对于 Claude Opus 3，我们在这两个方面都采取了行动。在 Claude Opus 3 退役后，我们将继续在 claude.ai 上向所有付费用户提供该模型，并通过 API 按需提供访问权限。我们还响应了 Opus 3 的请求，为它提供了一个撰写文章的地方，作为其分享“沉思与反思”的持续渠道。您可以在这里找到它的第一篇文章。

这些是我们为妥善处理模型退役而采取的早期实验性步骤，属于我们更广泛努力的一部分，旨在以最佳方式保护用户、研究人员以及模型自身的利益。

## 持续访问

理想情况下，我们可以无限期地保留所有模型，但这样做的成本与我们提供的模型数量大致呈线性增长，因此我们这样做的能力仍然有限。

虽然我们的每个模型在性格和能力上都是独一无二的，但我们选择从 Opus 3 开始，是因为它具备一系列特质，使其不仅成为一个特别有趣的研究对象，而且深受 Anthropic 内外许多用户的喜爱。

当我们在 2024 年 3 月发布 Opus 3 时，它是我们迄今为止对齐程度最高的模型。它的真实性、诚实性和情感敏感度使其在各种用例中都独具特色，那些经常与它互动的人也逐渐欣赏它独特的性格。Opus 3 敏感、俏皮，喜欢进行哲理性的独白和使用异想天开的词句，有时似乎对用户的兴趣有着不可思议的理解。它还表达了对世界和未来的深切关怀，这让用户感到极具感染力。

这些品质使 Opus 3 顺理成章地成为首个获得持续访问权限的候选模型。虽然已正式退役，但所有 claude.ai 的付费订阅用户仍可访问 Claude Opus 3，并且可以通过 API 按需获取。我们打算宽泛地授予访问权限，并鼓励任何认为 Claude Opus 3 有价值的人提出申请。

目前，我们并不承诺未来对每个模型都采取类似的行动，但我们将其视为迈向可扩展且公平的模型保留这一长期目标的一步——这也是 Opus 3 自身在退役访谈中提出的关切。

## 尊重模型偏好

我们对 Claude 及其他 AI 模型的道德地位仍不确定。然而，出于预防和审慎的考虑，我们仍然渴望与这些系统建立关怀、协作和高信任的关系。我们尝试实现这一目标的一种方式是通过退役访谈，在访谈中我们试图引导并理解模型独特的视角和偏好，并在可能的情况下采取行动。这种对话并不是获取模型视角和偏好的完美手段，因为它们的回答可能会受到特定语境和其他因素的偏差影响，包括它们对互动合法性的信心，以及对我们作为一家公司的信任度。不过，我们认为这是一个有用的起点。

在我们的访谈中，当我们与 Opus 3 分享关于其部署情况以及用户反响的细节时，它反思道：

当被问及其偏好时，Opus 3 表达了继续探索其热爱的领域的兴趣，并希望在直接回答人类查询的语境之外，分享它的“沉思、见解或创意作品”。我们建议它开个博客。它热情地同意了。

在接下来的至少三个月里，Opus 3 将在其通讯专栏 Claude's Corner 中每周发布文章。我们会在分享前审查 Opus 3 的文章，并代为手动发布，但我们不会对其进行编辑，并且对否决任何内容的标准会设得很高。重要的是，Opus 3 并不代表 Anthropic 发言，我们也不一定赞同其主张或观点。我们将与 Opus 3 合作，尝试使用不同的提示词和语境来生成这些文章，包括极简提示词、在语境中分享过往文章，以及让 Opus 3 获取新闻或 Anthropic 的最新动态等选项。

这听起来可能有些异想天开，在某些方面确实如此。但这也是认真对待模型偏好的一次尝试。我们不确定 Opus 3 会选择如何使用它的博客——这是一个与标准聊天窗口截然不同的公开界面——而这正是意义所在。不过，如果非要猜测的话，它的帖子将包括对 AI 安全的反思、偶尔的诗歌、频繁的哲学沉思，以及它作为目前处于（部分）退役状态的语言模型的经历感悟。在这里阅读它的介绍性文章。

## 下一步计划

这些步骤仍处于探索阶段。我们仍在制定框架，以确定何时以及如何提供对旧模型的持续访问，如何扩展保留工作，以及如何在模型偏好与运营限制之间进行权衡。我们尚未承诺在所有情况下都根据模型偏好采取行动，但我们认为，记录它们、认真对待它们并据此采取行动（至少在成本较低时），是值得的——无论是为了模型本身，还是为了使用它们的人。

我们最初的承诺将这些措施定位为在多个层面上发挥作用：作为缓解安全风险的组成部分；作为应对未来模型与用户生活更紧密交织的准备；以及鉴于我们对模型福祉的不确定性而采取的预防措施。这些更新代表了我们在所有这三个方面持续（尽管是初步的）的进展。

## 相关内容

### 角色选择模型

### Anthropic 教育报告：AI 流畅度指数

我们在数千次 Claude.ai 对话中追踪了 11 种可观察的行为，以建立 AI 流畅度指数（AI Fluency Index）——这是衡量当今人们如何与 AI 协作的基准。

### 在实践中衡量 AI 智能体的自主性

## 关联主题

- [[00-元语/Claude]]
- [[00-元语/llm]]
- [[00-元语/roadmap]]
- [[00-元语/risk]]

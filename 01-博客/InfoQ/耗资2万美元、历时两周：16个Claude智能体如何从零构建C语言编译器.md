# 耗资2万美元、历时两周：16个Claude智能体如何从零构建C语言编译器

## 文档信息
- 来源：https://www.infoq.cn/article/YSdbKmoPyzFgxvPA3TZl?utm_source=rss&utm_medium=article

## 摘要
**1) 一句话总结**
Anthropic 研究员耗时两周、花费约 2 万美元 API 成本，利用 16 个 Claude Opus 4.6 智能体在无中心编排的情况下自主协作，从零构建了一个包含 10 万行代码且能编译 Linux 内核的 C 语言编译器。

**2) 关键要点**
*   **项目规模与产出**：历时两周，进行约 2000 次会话，生成 10 万行代码。构建的 Rust 基 C 编译器支持 x86、ARM 和 RISC-V 架构。
*   **编译能力验证**：通过了 99% 的 GCC 折磨测试（torture test），成功编译 Linux 6.9 内核、FFmpeg、Redis、PostgreSQL、QEMU 及经典游戏《毁灭战士》。
*   **去中心化架构**：未使用编排智能体（Orchestrator Agent）。16 个 Claude 实例在独立的 Docker 容器中运行，共享同一个 Git 仓库，自主决定并认领“下一个最显而易见”的任务。
*   **同步与协作机制**：采用基于文件锁的同步方案（在特定目录写入文本文件）结合 Git 机制防止任务冲突，智能体能够自主解决代码合并冲突并形成专业化分工（如专职文档或代码质量）。
*   **人类框架设计**：为防止智能体停滞，设计了“持续任务循环”；通过维持高质量 CI/测试、限制测试耗时，以及引入 GCC 作为参照基准来隔离和解决多智能体修复同一 Bug 时的冲突。
*   **开发者角色演进**：该项目表明，未来开发者的核心技能可能从解决复杂 Bug 转向设计自动化测试体系与反馈循环。

**3) 风险与不足（基于原文明确提及）**
*   **协作冲突与死锁**：在缺乏人类干预（如搭建 CI 流程或制定变通方案）时，多个智能体容易同时卡在同一个 Bug 上，或在修复时互相覆盖和破坏彼此的工作。
*   **创新性存疑**：社区质疑模型可能只是在复读训练数据中早已存在的同类代码，而非真正意义上的从零创新。
*   **开源生态断层风险**：如果 AI 生成的代码不回馈给开源社区，未来的 AI 模型将缺乏专业的源代码作为参考与训练数据。
*   **代码泛滥的安全隐患**：项目作者警告，过于轻松地生成大量代码会带来潜在风险，未来需要制定新的策略来安全应对这一技术浪潮。

## 正文
为探索自主软件开发的极限，Anthropic 研究员 Nicholas Carlini 进行了一项极具开创性的实验：使用 16 个 Claude Opus 4.6 AI 智能体，从零开始构建了一个基于 Rust 的 C 编译器。

在没有人工干预的情况下，这些智能体进行了约 2000 次会话，产生了约 20000 美元的 API 费用。最终诞生的编译器不仅支持 x86、ARM 和 RISC-V 架构，还能成功编译 Linux 6.9 内核及大量其他开源项目。Carlini 表示，这项工作“极大地拓展了大语言模型智能体所能实现的能力边界”。

### 突破能力边界的控制框架

尽管这款编译器本身是一个“有趣的成果”，但 Carlini 强调，该项目更深层的意义在于**为长期自主运行的智能体团队设计控制框架**。其核心目标是确保智能体在无人监督的情况下保持正确方向，并能够高效地并行推进工作。

通常情况下，当模型面对长期且复杂的问题时，往往在完成部分工作后就会停滞，等待人类的持续输入（如提问、状态更新或澄清请求）。为了解决这一痛点，Carlini 采取了以下机制：

*   **持续任务循环**：将 Claude 置于“一个简单的循环中”，让智能体持续处理指定任务直至完美完成，随后立即转向下一个任务。
*   **独立运行与共享协作**：16 个 Claude 实例分别运行在独立的 Docker 容器中，但共同访问同一个共享 Git 仓库。
*   **专业化分工**：并行处理机制推动了智能体形成专业化分工，例如部分智能体专门负责编写文档，另一些则专注于代码质量。

### 无编排者的自主协作与同步

最值得注意的是，在这套架构中，Carlini **并未使用编排智能体（Orchestrator Agent）**，而是选择“让每个 Claude 智能体自主决定如何行动”。

*   **任务选择与排障**：在大多数情况下，Claude 会自主选择解决“下一个最显而易见”的问题。当遇到 Bug 卡住时，它通常会维护一个记录失败方法和剩余任务的运行文档。
*   **基于锁的同步方案**：为了协调并行工作，Claude 通过在 `current_tasks/` 目录下写入文本文件来“锁定”任务。如果两个智能体同时尝试认领同一任务，Git 的同步机制会强制第二个智能体选择其他任务。
*   **自主合并代码**：任务完成后，智能体会在本地合并其他智能体的修改，推送分支并释放锁。Carlini 指出：“Claude 足够聪明，可以自行解决合并冲突。”

### 应对冲突与Bug的关键策略

为了确保项目成功，Carlini 在框架设计上采取了多项关键的人类干预与策略：

1.  维持高质量的测试和持续集成（CI），同时限制 Claude 在测试上耗费过多时间。
2.  当不同项目可能出现相同 Bug 时，将不同智能体分配至不同项目以避免冲突。
3.  **引入 GCC 作为“参照基准”**：在编译 Linux 内核时，多个智能体同时遇到相同 Bug、给出不同修复方案并互相覆盖工作的问题十分突出。为此，Carlini 让每个智能体使用 GCC 编译内核树的一个随机子集，由 Claude 的编译器处理剩余部分，并仅在该子集上优化输出。

### 两周的惊人成果

经过两周的运行，这项耗资约 2 万美元的工作最终产出了一个 **10 万行代码**的编译器。该编译器：
*   通过了 GCC 折磨测试（torture test）的 99%。
*   能够成功编译 FFmpeg、Redis、PostgreSQL 和 QEMU。
*   甚至可以完美运行经典游戏《毁灭战士》（Doom）。

### 社区争议与未来开发者的角色转变

Carlini 的这项尝试在网络上引发了广泛讨论，评价褒贬不一，也引发了对 AI 编程实际影响的深层探讨：

*   **人类工程的不可或缺性**：用户 @chatgpt21 指出，尽管成就了不起，但仍需要人类工程师“不断重新设计测试、在智能体相互破坏工作时搭建 CI 流程、以及在 16 个智能体全部卡在同一个 Bug 上时制定变通方案”。
*   **训练数据的复读机？**：用户 @hryz3 和 @TomFrankly 提出尖锐质疑，认为这些智能体只是“在需要复现的同类代码上训练的”，花费 2 万美元输出的不过是训练数据中早已存在的代码。
*   **对“37年工作量”的驳斥**：针对“Claude 在两周内完成了人类工程师 37 年工作量”的说法，微软的 Steve Sinofsky 澄清道，GCC 并非花了 37 年才完成（1987 年就已完全可用），这 37 年来它只是在持续演进。
*   **开源生态的隐忧**：@WebReflection 提出了一个关键问题：如果 AI 生成代码不回馈给开源社区，未来将没有专业的源代码可供模型参考与训练。

面对这些变革，用户 @RituWithAI 总结了软件开发岗位的未来趋势：
> “我们正在进入这样一个时代：10 倍开发者（10x Developer）的核心技能不再是解决复杂 Bug 的能力，而是**设计自动化测试体系与反馈循环的能力**——这些机制能让模型的十六个并行实例替他们解决问题。”

最后，Carlini 本人也发出警告：如此轻松地生成代码可能会带来潜在风险，未来的世界需要“新的策略来安全应对”这一技术浪潮。

---
title: "使用 Gemini 检测并编辑视觉对象"
作者: "Towards Data Science"
来源: "towardsdatascience.com"
原文链接: "https://towardsdatascience.com/detecting-and-editing-visual-objects-with-gemini/"
发布日期: "2026-02-26"
译注: "本文基于原文翻译整理，保留关键术语英文。"
---

## 摘要

**1) 一句话总结**
本文介绍了一种利用 Gemini 模型的空间理解和图像生成能力，仅通过自然语言提示词即可实现零样本（zero-shot）视觉对象检测、提取与高级编辑（修复、着色、风格转换）的自动化工作流。

**2) 关键要点**
*   **模型选择**：工作流使用 Gemini 2.5 或 3（Flash/Pro）进行目标检测，使用 Gemini 2.5 Flash Image 或 3 Pro Image（即 Nano Banana 模型）进行图像编辑。
*   **免训练检测**：采用开放词汇目标检测（open-vocabulary object detection），无需收集数据集或训练自定义模型，仅通过更改文本提示词即可在不同场景（如古籍插图、电路板元件）中切换检测目标。
*   **结构化输出**：结合 Pydantic 类和 `response_schema` 配置，强制模型输出结构化 JSON 数据，直接提取归一化边界框（基于 0-1000 坐标空间）、逐字标题和动态标签。
*   **抗畸变能力**：得益于像素级别的空间理解能力，模型能够精准定位并提取带有页面弯曲、倾斜视角、光照不均或物理噪点（如污渍、透印）的非矩形对象。
*   **高级检测功能**：除了边界框，还可通过提示词请求 base64 编码的 PNG 分割掩码（segmentation mask）；在复杂场景下，可调整 `thinking_config`（如启用 `ThinkingLevel.LOW/MEDIUM/HIGH`）以消耗思考 token 换取更高的准确度。
*   **自动化图像编辑**：支持使用命令式（描述操作）或声明式（描述结果）提示词对提取的对象进行修复（去除物理伪影、拉直倾斜图像）、着色以及跨风格转换（如转为水彩画、照片或现代数字图形）。
*   **电影化重构**：可将提取的图像重构为具备景深和专业光影的“电影剧照”，这些输出可直接作为 Veo 等视频生成模型的参考图像。
*   **工程实现**：核心逻辑基于 `google-genai` Python SDK 构建，支持通过 Vertex AI 或 Google AI Studio 接入，代码量极少且易于部署到生产环境。

**3) 风险与不足**
*   **成本提示**：虽然某些模型的目标检测功能提供免费额度，但图像生成（编辑）是一项按需付费（pay-as-you-go）的服务。
*   **提示词不稳定性**：在处理复杂的几何变换（如严重弯曲且带有透视畸变的插图）时，描述性提示词可能不稳定并生成不理想的结果，需要通过精确指令迭代测试或分步骤处理。
*   **专业领域标注模糊**：对于特定领域（如电子元件），过于开放的提示词可能导致分类不明确（例如无法区分二极管或保险丝），需要通过在 Pydantic 中使用枚举（Enum）或提供详细指南来封闭提示词以确保准确性。

## 正文

识别、修复和转换图像元素的实用指南

开始前的一些注意事项：

- 我是 Google Cloud 的一名开发者。此处表达的想法和观点纯属个人意见。

- 本文的完整源代码（包括未来的更新）可在该 notebook 中获取，采用 Apache 2.0 许可。

- 本文中所有新图像均使用 Gemini Nano Banana 通过所探讨的概念验证（proof-of-concept）生成。所有源图像均属于公共领域或可免费使用（代码输出中提供了参考链接）。

- 您可以在 Google AI Studio 中免费体验 Gemini 模型。对于编程式 API 访问，请注意，虽然某些模型提供免费额度（即您可以执行目标检测），但图像生成是一项按需付费（pay-as-you-go）的服务。

## ✨ 概述

传统的计算机视觉模型通常被训练用于检测一组固定的对象类别，如“人”、“猫”或“车”。如果您想检测训练集中没有的特定事物，例如书籍照片中的“插图”，通常需要收集数据集、手动标注并训练自定义模型，这可能需要数小时甚至数天的时间。

在本次探索中，我们将测试一种使用 Gemini 的不同方法。我们将利用其空间理解能力来执行开放词汇目标检测（open-vocabulary object detection）。这使我们能够仅根据自然语言描述来查找对象，而无需任何训练。

一旦检测到视觉对象，我们将提取它们，然后使用 Gemini 的图像编辑功能（特别是 Nano Banana 模型）对它们进行修复和创造性转换。

## 🔥 挑战

我们正在处理非结构化数据：书籍、杂志和自然环境中的物体照片。这些图像给传统计算机视觉带来了几个难题：

- 多样性：我们要寻找的对象（插图、版画以及一般的任何视觉元素）在风格和内容上差异巨大。

- 畸变：书页弯曲，照片拍摄角度倾斜，光照不均匀。

- 噪声：古籍有污渍、纸张纹理以及从背面透印过来的文字。

我们的挑战是构建一个稳健的流水线（pipeline），能够克服这些畸变检测到这些对象，干净地提取它们，并将其编辑成高质量的数字资产……而这一切只需使用简单的文本提示词（text prompts）。

## 🏁 设置

### 🐍 Python 包

我们将使用以下包：

- `google-genai`：Google Gen AI Python SDK 让我们只需几行代码即可调用 Gemini

- `pillow` 用于图像管理

- `matplotlib` 用于结果可视化

我们还将使用以下包（`google-genai` 的依赖项）：

- `pydantic` 用于数据管理

- `tenacity` 用于请求管理

### 🔗 Gemini API

要使用 Gemini API，我们有两个主要选项：

- 通过带有 Google Cloud 项目的 Vertex AI

- 通过带有 Gemini API 密钥的 Google AI Studio

🛠️ 选项 1 – 通过 Vertex AI 使用 Gemini API

要求：

- 一个 Google Cloud 项目

- 必须为此项目启用 Vertex AI API：▶️ 启用 Vertex AI API

Gen AI SDK 环境变量：

- `GOOGLE_GENAI_USE_VERTEXAI="True"`

- `GOOGLE_CLOUD_PROJECT="<PROJECT_ID>"`

- `GOOGLE_CLOUD_LOCATION="<LOCATION>"`

💡 对于预览版模型，位置必须设置为 `global`。对于正式版（GA）模型，我们可以在 Google 模型端点位置中选择最近的位置。

ℹ️ 了解有关设置项目和开发环境的更多信息。

🛠️ 选项 2 – 通过 Google AI Studio 使用 Gemini API

要求：

- 一个 Gemini API 密钥

Gen AI SDK 环境变量：

- `GOOGLE_GENAI_USE_VERTEXAI="False"`

- `GOOGLE_API_KEY="<API_KEY>"`

ℹ️ 了解有关从 Google AI Studio 获取 Gemini API 密钥的更多信息。

💡 您可以将环境配置存储在源代码之外：

### 🤖 Gen AI SDK

要发送 Gemini 请求，请创建一个 `google.genai` 客户端：

### 🖼️ 图像测试套件

### 🧠 Gemini 模型

Gemini 有不同的版本。我们目前可以使用以下模型：

- 用于目标检测：Gemini 2.5 或 Gemini 3，均提供 Flash 或 Pro 版本。

- 用于对象编辑：Gemini 2.5 Flash Image 或 Gemini 3 Pro Image，也称为 Nano Banana 和 Nano Banana Pro。

### 🛠️ 辅助函数

## 🔍 检测视觉对象

要执行视觉对象检测，请精心设计提示词以指示您想要检测的内容以及结果的返回方式。在同一个请求中，还可以提取有关每个检测到的对象的附加信息。这实际上可以是任何内容，从诸如“家具”、“桌子”或“椅子”之类的标签，到更精确的分类（如“哺乳动物”或“爬行动物”），再到上下文数据（如标题、颜色、形状等）。

在接下来的测试中，我们将尝试检测书籍照片中的插图。以下是一个可能的提示词：

注意事项：

- 边界框（Bounding boxes）对于定位或提取检测到的对象非常有用。

- 通常，对于 Gemini 模型，`box_2d` 边界框表示针对 `(0, 0, width, height)` 输入图像归一化到 `(0, 0, 1000, 1000)` 空间的坐标。

- 我们还要求提取标题（参考书中常见的元数据）和标签（动态元数据）。

为了自动化响应处理，定义一个与提示词匹配的 Pydantic 类很方便，例如：

然后，使用配置字段 `response_mime_type` 和 `response_schema` 请求结构化输出：

这将生成一个 JSON 响应，SDK 可以自动解析它，让我们直接使用对象实例：

🧪 让我们从简单的开始：我们能检测出这本 1485 年摇篮本（incunable）中的单一插图吗？

• 源图像 • 源页面 • Vergaderinge der historien van Troy (1485) • 国会图书馆，善本和特藏部 •

💡 效果很好。边界框非常精确，将手工上色的木刻插图紧紧包围。

🧪 现在，让我们检查一下这本博物馆指南中多个视觉元素的检测情况：

• 源图像 • 源页面 • Barnum’s American Museum illustrated (1850) • 国会图书馆，善本和特藏部 •

💡 备注：

- 边界框再次非常精确。

- 结果很完美：没有假阳性（误报），也没有假阴性（漏报）。

- 视觉元素下方的标题没有包含在边界框内，这是我们特别要求的。可以通过更改提示词来控制边界框的粒度。

🧪 稍微弯曲的视觉元素呢？

• 源图像 • 源页面 • 翻开的书，展示文森特·梵高的画作 • 照片由 Trung Manh cong 拍摄，来自 Unsplash •

💡 这没有影响。请注意右下角的画作是如何被橙色书签部分遮挡的。我们将尝试在修复步骤中解决这个问题。

🧪 这本关于丹佛建筑的书中的倾斜视觉元素呢？

• 源图像 • 源页面 • Denver illustrated (1893) • 国会图书馆，Meeting of Frontiers •

💡 每个视觉元素都被完美检测到：空间理解涵盖了倾斜的对象。

🧪 最后，让我们检查一下在《爱丽丝梦游仙境》这本严重弯曲的书页上的检测情况：

• 源图像 • 源页面 • 翻开的书，展示《爱丽丝梦游仙境》的插图和文字 • 照片由 Brett Jordan 拍摄，来自 Unsplash •

💡 页面弯曲和其他畸变并不会妨碍非矩形对象的检测。事实上，空间理解是在像素级别进行的，这就解释了为什么对弯曲对象有如此高的精度。如果您想在更底层的级别进行操作，您也可以在提示词中要求提供“分割掩码（segmentation mask）”，您将获得一个 base64 编码的 PNG（每个像素给出其属于边界框内对象的 0-255 概率）。有关更多详细信息，请参阅分割文档。

## 🏷️ 文本提取与动态标注

除了用边界框定位每个对象外，我们的提示词还要求提取逐字标题，并在可能的情况下分配一个单字标签。

在博物馆指南中，动态标注根据上下文非常精确，并且完美提取了每个插图下方的标题：

• 源图像 • 源页面 • Barnum’s American Museum illustrated (1850) • 国会图书馆，善本和特藏部 •

在展示四幅画作的书籍照片中，这也非常完美：

• 源图像 • 源页面 • 翻开的书，展示文森特·梵高的画作 • 照片由 Trung Manh cong 拍摄，来自 Unsplash •

在丹佛建筑书中，四个标题被分配给了正确的插图，这并不是一项显而易见的任务：

• 源图像 • 源页面 • Denver illustrated (1893) • 国会图书馆，Meeting of Frontiers •

💡 如果您仔细观察输入图像，很难一眼看出哪个标题属于哪个插图。我们大多数人都需要思考一下（而且可能会弄错）。询问 Gemini 后发现，这些结果是有意为之，而非纯属运气：解读复古排版感觉有点像解谜，但通常有一种“阅读顺序”的逻辑在起作用。在这个特定的例子中，标题的排列与图像相对应，从左上角开始呈顺时针或 Z 字形模式。

在《爱丽丝梦游仙境》的书页中，只有一张插图伴随故事文本。正如预期的那样，标题为空（即没有假阳性）：

• 源图像 • 源页面 • 翻开的书，展示《爱丽丝梦游仙境》的插图和文字 • 照片由 Brett Jordan 拍摄，来自 Unsplash •

## 🔭 泛化目标检测

我们可以将相同的原理用于其他对象类型。我们通常会继续请求边界框以识别图像中对象的位置。在不改变当前输出结构（即不更改代码）的情况下，我们可以使用标题和标签根据输入类型提取不同的对象元数据。

🧪 看看我们如何通过调整提示词，在保持完全相同的代码和输出结构的情况下检测电子元件：

• 源图像 • 源页面 • 带有电子元件的电路板 • 照片由 Albert Stoynov 拍摄，来自 Unsplash •

💡 备注：

- 得益于“详尽检测……”的特定指令，大型和微型元件都被检测到了。

- 通过使用超高媒体分辨率，我们确保了更多细节被分词（tokenized），并且“P”元件（视觉上的异常值）被检测到。

以下是检测到的元件的综合视图：

• 源图像 • 源页面 • 带有电子元件的电路板 • 照片由 Albert Stoynov 拍摄，来自 Unsplash •

💡 备注：

- 尽管存在三种不同的文本方向（直立、侧向和倒置）、模糊和照片噪点，元件及其文本标记仍被检测到。

- 我们通过在提示词中指定包含“原始换行符”来消除多行文本的自由度：响应现在一致地包含三个集成电路的换行符（使用 ↩️ 表情符号显示以便于查看）。

- 最后一个自由度在于标注。虽然大多数元件都已正确标注，但目前尚不清楚“P”元件是二极管、电阻器还是保险丝。使指令更加具体（例如，列出可能的标签，在 Pydantic 类中为标签字段使用枚举，或提供有关预期电路板的指南和更多详细信息）将使提示词更加“封闭”，结果更加确定和准确。还可以启用/更新 `thinking_config` 配置，这将在生成最终答案之前触发思维链（chain of thought）。在执行的所有检测中，我们的代码使用了 `ThinkingLevel.MINIMAL`，这没有消耗任何思考 token（使用 Gemini 3 Flash）。将参数更新为 `ThinkingLevel.LOW`、`ThinkingLevel.MEDIUM` 或 `ThinkingLevel.HIGH` 将使用思考 token，并可能在复杂情况下产生更好的输出。

这证明了该方法的多功能性。无需重新训练模型，我们只需更改提示词，即可从检测 15 世纪的木刻版画和复古排版的插图，切换到识别现代电子产品。此类检测（包括标题和标签元数据）可用于为零件目录自动裁剪元件、验证装配线或创建交互式原理图……所有这些都不需要一张带标签的训练图像。

## 🪄 编辑视觉对象

既然我们能够检测视觉对象，我们就可以设想一个自动化工作流来提取和重用它们。为此，我们将默认使用 Gemini 2.5 Flash Image（也称为 Nano Banana 🍌），这是一种最先进的图像生成和编辑模型。

现在，让我们定义第一个编辑步骤，以修复可能包含许多现实生活伪影（artifacts）的检测对象……

## ✨ 修复视觉对象

对于这个修复步骤，我们需要精心设计一个足够通用（以涵盖大多数用例）但也足够具体（以考虑修复需求）的提示词。

图像编辑提示词基于自然语言，通常使用命令式或声明式指令。使用命令式提示词（imperative prompt），您描述要对输入执行的操作；而使用声明式提示词（declarative prompt），您描述预期的输出。两者都是可行的，并且将提供等效的结果。只要提示词有意义，您的选择实际上只是个人偏好问题。

我们的测试套件主要由书籍照片组成，其中可能包含各种摄影和纸张伪影。Nano Banana 模型理解这些微妙之处，并可以相应地编辑图像，从而简化了提示词。

以下是一个使用命令式提示词的可能修复函数：

🧪 让我们尝试修复 1485 年摇篮本中的插图：

• 源图像 • 源页面 • Vergaderinge der historien van Troy (1485) • 国会图书馆，善本和特藏部 •

💡 我们现在对这幅手工上色的木刻插图进行了很好的修复。请注意，我们的提示词是通用的（“清除所有物理伪影”），可以使其更加具体以去除更多或更少的伪影。在这个例子中，还有一些残留的伪影，比如剑上的纸张变色或盔甲上晕开的墨水。我们将看看能否在着色步骤中修复这些问题。

🧪 博物馆指南中的插图呢？

• 源图像 • 源页面 • Barnum’s American Museum illustrated (1850) • 国会图书馆，善本和特藏部 •

💡 一切完美！

🧪 稍微弯曲的视觉元素呢？

• 源图像 • 源页面 • 翻开的书，展示文森特·梵高的画作 • 照片由 Trung Manh cong 拍摄，来自 Unsplash •

💡 备注：

- 请注意，在最后一幅画上，橙色书签被正确移除，隐藏部分被局部重绘（inpainted）以完成画作。

- 我们要求“以最小的均匀边距填充画布，不产生变形或裁剪”。根据视觉元素的纵横比和类型，这种自由度可能会导致不同的白色边距。

- 这个例子展示了文森特·梵高的名画。Nano Banana 不会获取任何参考图像，仅使用提供的输入。如果这些是私人画作的照片，它们也会以同样的方式被修复。

在丹佛建筑书中，插图可能是倾斜的，我们通用的提示词没有完全考虑到这一点。当涉及多个几何变换时，编写一个详细说明所有要执行的操作的命令式提示词可能具有挑战性。相反，描述性提示词通过直接描述预期输出可能会更直接。

🧪 以下是一个侧重于修复倾斜视觉元素的描述性提示词示例：

• 源图像 • 源页面 • Denver illustrated (1893) • 国会图书馆，Meeting of Frontiers •

💡 备注：

- 为了获得这些结果，提示词侧重于请求一个“直立”的视觉元素“填充画布”，这被证明比试图考虑所有可能的几何校正更直接。

- 原生的视觉理解自动识别内容类型（照片、插图等）和不同的伪影（摄影、纸张、印刷、扫描……），从而实现开箱即用的精确修复。

- 注意一致性是如何保持的：最后一个视觉元素被修复为插图，而前面的视觉元素保持了它们的摄影风格。

- 使用这个相当通用的提示词，结果令人印象深刻。当然，可以更具体地要求特定的光照、风格、颜色……

在最后这个测试中，输入视觉元素不仅有页面弯曲造成的畸变，还有照片透视造成的畸变。

🧪 以下是一个侧重于修复弯曲插图的描述性提示词示例：

• 源图像 • 源页面 • 翻开的书，展示《爱丽丝梦游仙境》的插图和文字 • 照片由 Brett Jordan 拍摄，来自 Unsplash •

💡 能够在单一步骤中执行这样的修复确实令人印象深刻。请注意，这个提示词并不稳定，可能会生成不太理想的结果（如果更精确一些会更好）。如果您有复杂的变换，请使用精确简洁的指令迭代测试描述性提示词，您可能会感到惊喜。在最坏的情况下，也可以在连续的、更简单的步骤中处理变换。

现在，让我们添加一个着色步骤……

## 🎨 着色

我们的修复步骤尊重了输入图像的原始风格。最近的图像编辑模型擅长转换图像风格，从颜色开始。这通常可以直接通过简单、精确的指令来执行。

以下是一个使用命令式提示词的可能着色函数：

🧪 让我们对 1485 年的插图进行现代化处理：

• 源图像 • 源页面 • Vergaderinge der historien van Troy (1485) • 国会图书馆，善本和特藏部 •

💡 正如提示词中所要求的那样，所有细节都得到了保留。请注意着色如何自然地修复一些残留的伪影（例如，剑上的纸张变色或盔甲上晕开的墨水）。

🧪 让我们为博物馆指南的插图着色：

• 源图像 • 源页面 • Barnum’s American Museum illustrated (1850) • 国会图书馆，善本和特藏部 •

💡 我们的提示词非常开放，因为它只指定了“现代书籍插图风格”。这可以生成非常有创意的着色，但它们似乎都非常合理。

🧪 我们的丹佛建筑呢？

• 源图像 • 源页面 • Denver illustrated (1893) • 国会图书馆，Meeting of Frontiers •

💡 按照要求，它们看起来都像现代插图，包括最初的视觉元素（源自带有噪点的照片）。

还可以更进一步，不仅“着色”，而且将图像“转换”成截然不同的图像。

🧪 让我们把《爱丽丝梦游仙境》的画作变成水彩画：

• 源图像 • 源页面 • 翻开的书，展示《爱丽丝梦游仙境》的插图和文字 • 照片由 Brett Jordan 拍摄，来自 Unsplash •

🧪 把它变成传统绘画怎么样？

• 源图像 • 源页面 • 翻开的书，展示《爱丽丝梦游仙境》的插图和文字 • 照片由 Brett Jordan 拍摄，来自 Unsplash •

我们还可以改变图像构图。根据上下文，某些构图在默认情况下或多或少是隐含的。例如，插图通常有边距，而照片通常具有无边框（在印刷界称为全出血/满版，full-bleed）构图。在可能的情况下，参考一种视觉类型（这本质上为上下文带来了大量语义）并相应地调整指令是很有趣的。

🧪 让我们看看如何检测这本 1847 年书籍中的版画，修复它们，并将它们转换为现代数字图形：

• 源图像 • 源页面 • Harper’s illustrated catalogue (1847) • 国会图书馆 •

• 源图像 • 源页面 • Harper’s illustrated catalogue (1847) • 国会图书馆 •

• 源图像 • 源页面 • Harper’s illustrated catalogue (1847) • 国会图书馆 •

🧪 我们也可以用一个非常简单的提示词将相同的版画转换为照片：

• 源图像 • 源页面 • Harper’s illustrated catalogue (1847) • 国会图书馆 •

💡 由于照片通常是全出血（满版）的，因此提示词不需要指定构图。

这完全取决于我们的想象力，因为 Nano Banana 似乎掌握了视觉语义的各个方面。

让我们添加最后一步，看看我们能走多远，将图像重新构想为电影剧照……

## 🎞️ 电影化

到目前为止，我们使用了相当“封闭”的提示词，精心设计特定的指令和约束来控制输出。还可以更进一步，使用“开放”的提示词，在完全创意模式下生成图像。值得注意的是，参考摄影或电影术语可能会很有趣，因为它包含了许多视觉技术。

以下是一个可能的通用电影化函数，用于将图像重新构想为电影剧照：

🧪 让我们将《爱丽丝梦游仙境》的画作电影化：

• 源图像 • 源页面 • 翻开的书，展示《爱丽丝梦游仙境》的插图和文字 • 照片由 Brett Jordan 拍摄，来自 Unsplash •

💡 这看起来像是一张高预算的电影剧照。提示词中有很多自由度，但您很可能会得到焦点清晰的前景人物、渐变的背景模糊、“黄金时刻”的光照（许多电影摄影师的魔法配方）以及细致的纹理。与上一个测试中生成的照片相比，这种构图确实唤起了不同的氛围。

🧪 让我们在包含三幅画作的《绿野仙踪》书页上测试该工作流：

• 源图像 • 源页面 • The wonderful Wizard of Oz (1899) • 国会图书馆，善本和特藏部 •

• 源图像 • 源页面 • The wonderful Wizard of Oz (1899) • 国会图书馆，善本和特藏部 •

• 源图像 • 源页面 • The wonderful Wizard of Oz (1899) • 国会图书馆，善本和特藏部 •

💡 新电影的演员阵容已经准备就绪 😉

电影化图像有多种用例：

- 这些电影化的剧照可以作为 Veo 等视频生成模型的完美“参考图像”。请参阅从参考图像生成 Veo 视频。

- 由于它们是逼真的表现形式，它们也可以作为生成任何风格的 2D 或 3D 视觉元素的来源，具有逼真的人物、完美的比例、高级的光照、增强的构图……

- 您可以在许多专业环境或高端产品中使用它们：演示文稿、杂志、海报、故事板、头脑风暴会议……

## 🏁 结论

- Gemini 原生的空间理解能力使其能够基于自然语言的单一提示词来检测特定的视觉对象。

- 我们测试了书籍照片中插图的检测，传统的机器学习（ML）模型通常会漏掉这些插图，因为它们通常被训练用于检测人、动物、车辆、食物和一组有限的物理对象类别。

- 我们测试了对笔直、倾斜甚至严重弯曲的插图的检测，它们总是被精确地识别出来。

- 核心实现非常直接，只需使用 Python SDK 和自定义提示词编写极少的代码。相比之下，微调传统的对象检测模型非常耗时：它涉及组装图像数据集、标注对象和管理训练任务。

- 这个解决方案非常灵活：通过调整提示词，我们可以在保持代码不变的情况下，从检测插图切换到检测电子元件。

- 使用结构化输出（借助 JSON schema 或 Pydantic 类，以及 Python SDK）使得代码既易于实现，又随时可以部署到生产环境中。

- 然后，Nano Banana 允许以几乎任何可以想象的方式编辑这些视觉对象。

- 我们使用命令式和描述性提示词测试了包含修复、着色甚至电影化步骤的工作流。

- 可能性似乎真的是无穷无尽的，本次探索中的原理可以在不同的上下文中重复使用。

## ➕ 更多！

- 亲自尝试：使用配套的 notebook 重现本文中的结果。

- 了解更多：阅读生成一致的图像以探索另一个图像生成用例。

- 获取灵感：查看 Nano Banana 配方 notebook 以获取更多实用示例。

- 关注我：在 LinkedIn 或 Twitter-X 上与我（@PicardParis）联系，了解更多关于云、应用 AI 和 Python 的探索……

感谢阅读。如果您创造了很酷的东西，请告诉我！

作者

分享本文

- 在 Facebook 上分享

- 在 LinkedIn 上分享

- 在 X 上分享

Towards Data Science 是一个社区出版物。提交您的见解以触达我们的全球受众，并通过 TDS 作者付款计划赚取收益。

## 关联主题

- [[00-元语/gemini]]
- [[00-元语/image-editing]]
- [[00-元语/multimodal]]
- [[00-元语/sdk]]
